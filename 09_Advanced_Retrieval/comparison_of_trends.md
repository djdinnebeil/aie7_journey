| Metric                     | Trend Across Both Datasets                                                                                                                                  | Explanation                                                                                                |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| **Naive Retrieval**        | ✅ **Consistently low cost and latency**<br>⚠️ *Lower context recall and factual correctness in both cases*                                                  | Naive remains efficient but less reliable for deeper reasoning or structured data                          |
| **BM25**                   | ✅ **Fast and cheap in both**<br>⚠️ *Strong context recall, weak factual correctness and answer relevancy in customer data*                                  | Performs better in structured data (docs) due to term matches; more noise-prone in unstructured complaints |
| **Multi-Query**            | ✅ **Most expensive and slowest in both**<br>✅ *Best faithfulness, factual correctness stays strong*                                                         | Consistent high-quality generation at high cost; well-suited to both corpora                               |
| **Parent-Document**        | ✅ **Cheapest and most compact in both**<br>⚠️ *Better recall and relevancy in official docs*<br>⚠️ *More noise and lower correctness in customer data*      | More effective when context structure is cleaner (e.g., docs)                                              |
| **Contextual Compression** | ✅ **Low cost and noise in both**<br>✅ *High factual correctness in both*<br>⚠️ *Slight drop in recall with customer complaints*                             | Compression shines in both datasets, especially when clarity and brevity are needed                        |
| **Ensemble**               | ✅ **Most costly and token-heavy in both**<br>⚠️ *Good relevancy, but lower factual correctness in customer data*                                            | Overhead remains high; stability in context-heavy use cases                                                |
| **Semantic Chunking**      | ✅ **Very strong in both datasets**<br>✅ *Top performer in latency, relevancy, and faithfulness*<br>⚠️ *Slight drop in factual correctness on official docs* | Maintains strong balance, though structured documents expose slight weakness in completeness               |


| Aspect                           | Verdict                                                                                                                                           |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Runtime/Cost Trends**          | ✅ **Stable across datasets** — Naive and BM25 remain fastest and cheapest; Multi-Query and Ensemble are always the most expensive                 |
| **Faithfulness & Correctness**   | ✅ **Multi-Query, Semantic, and Compression lead consistently** — regardless of dataset                                                            |
| **Recall and Noise Sensitivity** | ⚠️ **Dataset-sensitive** — Parent and Naive perform worse in customer complaints due to structure variability; Contextual Compression more stable |
| **Top Tradeoff Candidates**      | ✅ **Semantic and Contextual Compression** remain excellent middle-ground choices in both scenarios                                                |
