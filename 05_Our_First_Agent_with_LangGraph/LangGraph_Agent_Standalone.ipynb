{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ef2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"LangGraph Session05 - Standalone Agent\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad0c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a56fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, requests\n",
    "from pprint import pprint\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69da3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for the agent to use (weather, Wikipedia search, fun facts, and random color selection)\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Returns a dummy weather report for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "@tool\n",
    "def wiki_search(query: str) -> str:\n",
    "    \"\"\"Searches Wikipedia for a summary of the given query.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"https://en.wikipedia.org/api/rest_v1/page/summary/{query.replace(' ', '_')}\")\n",
    "        data = response.json()\n",
    "        return data.get(\"extract\", \"No summary available.\")\n",
    "    except Exception as e:\n",
    "        return f\"Wiki search failed: {e}\"\n",
    "\n",
    "@tool\n",
    "def fun_fact(topic: str) -> str:\n",
    "    \"\"\"Returns a fun fact about the given topic.\"\"\"\n",
    "    return f\"Did you know that {topic} has a fascinating history?\"\n",
    "\n",
    "@tool\n",
    "def random_color(colors: list[str]) -> str:\n",
    "    \"\"\"Randomly selects a color from a given list of strings.\"\"\"\n",
    "    print(f\"[TOOL] Choosing from: {colors}\")\n",
    "    return random.choice(colors) if colors else \"No colors provided.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e4f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the tool collection and initialize the OpenAI model with tool binding\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_belt = [get_weather, wiki_search, fun_fact, random_color]\n",
    "# Remove tool_dict - it's no longer needed with ToolNode\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "model = model.bind_tools(tool_belt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c1536a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent state structure using TypedDict for message handling\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d15db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent node that calls the model and generates responses\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b579aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ToolNode instance - replaces the manual tool_executor function\n",
    "tool_node = ToolNode(tool_belt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bcc72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the LangGraph with nodes, edges, and conditional routing\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"action\", tool_node)  # Use ToolNode instead of manual tool_executor\n",
    "\n",
    "def decide_next(state):\n",
    "    return \"action\" if state[\"messages\"][-1].tool_calls else END\n",
    "\n",
    "graph.add_conditional_edges(\"agent\", decide_next, {\"action\": \"action\", END: END})\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "compiled_graph = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121e429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test prompts to demonstrate different tool capabilities\n",
    "prompts = [\n",
    "    \"What is the weather in Parsippany?\",\n",
    "    \"Search Wikipedia for information about Declarationism.\",\n",
    "    \"Tell me a fun fact about ice cream.\",\n",
    "    \"Pick a random color from ['red-blue-yellow', 'yellow-blue-red', 'blue-red-yellow'].\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2674cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¢ Prompt: What is the weather in Parsippany?\n",
      "üìç Node: agent\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kMoSHozok8uVKsCxYMbeAj8J', 'function': {'arguments': '{\"city\":\"Parsippany\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 130, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtJO4M5Gj8pe82ukBc7qRzTVWrRBS', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--18abc587-6a81-4718-bbc6-495a5b1134d2-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Parsippany'}, 'id': 'call_kMoSHozok8uVKsCxYMbeAj8J', 'type': 'tool_call'}], usage_metadata={'input_tokens': 130, 'output_tokens': 16, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "üìç Node: action\n",
      "[ToolMessage(content='The weather in Parsippany is sunny.', name='get_weather', id='dd709eb3-b148-428d-b230-9d508559c645', tool_call_id='call_kMoSHozok8uVKsCxYMbeAj8J')]\n",
      "The weather in Parsippany is sunny.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "üü¢ Prompt: Search Wikipedia for information about Declarationism.\n",
      "üìç Node: agent\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ydQaXyFd3KoVL5JALBk0wl1V', 'function': {'arguments': '{\"query\":\"Declarationism\"}', 'name': 'wiki_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 129, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtJO5r2kJPUmues2Qg7Jk8kODQRU8', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--64751fb3-28f3-467a-a0ae-0b668c9c2772-0', tool_calls=[{'name': 'wiki_search', 'args': {'query': 'Declarationism'}, 'id': 'call_ydQaXyFd3KoVL5JALBk0wl1V', 'type': 'tool_call'}], usage_metadata={'input_tokens': 129, 'output_tokens': 16, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "üìç Node: action\n",
      "[ToolMessage(content='Originalism is a legal theory in the United States which bases constitutional, judicial, and statutory interpretation of text on the original understanding at the time of its adoption. Proponents of the theory object to judicial activism and other interpretations related to a living constitution framework. Instead, originalists argue for democratic modifications of laws through the legislature or through constitutional amendment.', name='wiki_search', id='d82696cf-9ca1-449b-92d4-5eeb0ef92b50', tool_call_id='call_ydQaXyFd3KoVL5JALBk0wl1V')]\n",
      "Originalism is a legal theory in the United States which bases constitutional, judicial, and statutory interpretation of text on the original understanding at the time of its adoption. Proponents of the theory object to judicial activism and other interpretations related to a living constitution framework. Instead, originalists argue for democratic modifications of laws through the legislature or through constitutional amendment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "üü¢ Prompt: Tell me a fun fact about ice cream.\n",
      "üìç Node: agent\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4IXVYWOzo7goVNxjMuamx96v', 'function': {'arguments': '{\"topic\":\"ice cream\"}', 'name': 'fun_fact'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 130, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtJO5ho8a7vKrvjkoorWiDVrDqLcW', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--abfea06f-215f-43f7-a1dd-0bc78d9a62f6-0', tool_calls=[{'name': 'fun_fact', 'args': {'topic': 'ice cream'}, 'id': 'call_4IXVYWOzo7goVNxjMuamx96v', 'type': 'tool_call'}], usage_metadata={'input_tokens': 130, 'output_tokens': 15, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "üìç Node: action\n",
      "[ToolMessage(content='Did you know that ice cream has a fascinating history?', name='fun_fact', id='9a99d819-d39c-4bc1-96ce-d358c95e1e21', tool_call_id='call_4IXVYWOzo7goVNxjMuamx96v')]\n",
      "Did you know that ice cream has a fascinating history?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "üü¢ Prompt: Pick a random color from ['red-blue-yellow', 'yellow-blue-red', 'blue-red-yellow'].\n",
      "üìç Node: agent\n",
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_RSUTXBR18YZwizd40yNY2nD6', 'function': {'arguments': '{\"colors\":[\"red-blue-yellow\",\"yellow-blue-red\",\"blue-red-yellow\"]}', 'name': 'random_color'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 141, 'total_tokens': 166, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': None, 'id': 'chatcmpl-BtJO63YeJhN9S04OHGpyePjpmIpNB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a676401d-c00b-436a-900e-58870f9a30bb-0', tool_calls=[{'name': 'random_color', 'args': {'colors': ['red-blue-yellow', 'yellow-blue-red', 'blue-red-yellow']}, 'id': 'call_RSUTXBR18YZwizd40yNY2nD6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 141, 'output_tokens': 25, 'total_tokens': 166, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "[TOOL] Choosing from: ['red-blue-yellow', 'yellow-blue-red', 'blue-red-yellow']\n",
      "üìç Node: action\n",
      "[ToolMessage(content='red-blue-yellow', name='random_color', id='9491a2c7-85c7-44a8-b1b5-13cb6fbf741b', tool_call_id='call_RSUTXBR18YZwizd40yNY2nD6')]\n",
      "red-blue-yellow\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the agent with streaming to process all test prompts and display results\n",
    "import asyncio\n",
    "\n",
    "async def run_streaming():\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nüü¢ Prompt: {prompt}\")\n",
    "        inputs = {\"messages\": [HumanMessage(content=prompt)]}\n",
    "        async for chunk in compiled_graph.astream(inputs, stream_mode=\"updates\"):\n",
    "            for node, values in chunk.items():\n",
    "                print(f\"üìç Node: {node}\")\n",
    "                pprint(values[\"messages\"])\n",
    "        print(values[\"messages\"][-1].content)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "await run_streaming()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d1f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
